{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef0b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from jumpstart.src.consts import *\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai = OpenAI()\n",
    "anthropic = Anthropic() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75fb80fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Generating oracle CSV with automatic data download...\n",
      "Using cached cards data: .build/cards.csv\n",
      "Oracle CSV generated: output/oracle_output.csv\n",
      "‚úÖ Oracle CSV generation complete!\n",
      "Oracle CSV generated: output/oracle_output.csv\n",
      "‚úÖ Oracle CSV generation complete!\n"
     ]
    }
   ],
   "source": [
    "import jumpstart.src.oracle\n",
    "from jumpstart.src.oracle import generate_oracle_csv\n",
    "\n",
    "# Regenerate the oracle CSV with automatic MTG data download and caching\n",
    "print(\"üîÑ Generating oracle CSV with automatic data download...\")\n",
    "generate_oracle_csv('pauper_cube_example_oracle.txt', 'output/oracle_output.csv')\n",
    "print(\"‚úÖ Oracle CSV generation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21175335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 450 cards from oracle_df\n",
      "Columns available: ['name', 'CMC', 'Type', 'Color', 'Color Category', 'Oracle Text', 'tags', 'MTGO ID', 'Power', 'Toughness']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>CMC</th>\n",
       "      <th>Type</th>\n",
       "      <th>Color</th>\n",
       "      <th>Color Category</th>\n",
       "      <th>Oracle Text</th>\n",
       "      <th>tags</th>\n",
       "      <th>MTGO ID</th>\n",
       "      <th>Power</th>\n",
       "      <th>Toughness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boros Elite</td>\n",
       "      <td>1</td>\n",
       "      <td>Creature ‚Äî Human Soldier</td>\n",
       "      <td>W</td>\n",
       "      <td>White</td>\n",
       "      <td>Battalion ‚Äî Whenever this creature and at leas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deftblade Elite</td>\n",
       "      <td>1</td>\n",
       "      <td>Creature ‚Äî Human Soldier</td>\n",
       "      <td>W</td>\n",
       "      <td>White</td>\n",
       "      <td>Provoke (Whenever this creature attacks, you m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Doomed Traveler</td>\n",
       "      <td>1</td>\n",
       "      <td>Creature ‚Äî Human Soldier</td>\n",
       "      <td>W</td>\n",
       "      <td>White</td>\n",
       "      <td>When this creature dies, create a 1/1 white Sp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elite Vanguard</td>\n",
       "      <td>1</td>\n",
       "      <td>Creature ‚Äî Human Soldier</td>\n",
       "      <td>W</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Faerie Guidemother</td>\n",
       "      <td>1</td>\n",
       "      <td>Sorcery ‚Äî Adventure</td>\n",
       "      <td>W</td>\n",
       "      <td>White</td>\n",
       "      <td>Target creature gets +2/+1 and gains flying un...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  CMC                      Type Color Color Category  \\\n",
       "0         Boros Elite    1  Creature ‚Äî Human Soldier     W          White   \n",
       "1     Deftblade Elite    1  Creature ‚Äî Human Soldier     W          White   \n",
       "2     Doomed Traveler    1  Creature ‚Äî Human Soldier     W          White   \n",
       "3      Elite Vanguard    1  Creature ‚Äî Human Soldier     W          White   \n",
       "4  Faerie Guidemother    1       Sorcery ‚Äî Adventure     W          White   \n",
       "\n",
       "                                         Oracle Text  tags  MTGO ID  Power  \\\n",
       "0  Battalion ‚Äî Whenever this creature and at leas...   NaN      NaN    1.0   \n",
       "1  Provoke (Whenever this creature attacks, you m...   NaN      NaN    1.0   \n",
       "2  When this creature dies, create a 1/1 white Sp...   NaN      NaN    1.0   \n",
       "3                                                NaN   NaN      NaN    2.0   \n",
       "4  Target creature gets +2/+1 and gains flying un...   NaN      NaN    NaN   \n",
       "\n",
       "   Toughness  \n",
       "0        1.0  \n",
       "1        1.0  \n",
       "2        1.0  \n",
       "3        1.0  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data files\n",
    "oracle_df = pd.read_csv('output/oracle_output.csv')\n",
    "print(f\"Loaded {len(oracle_df)} cards from oracle_df\")\n",
    "print(f\"Columns available: {list(oracle_df.columns)}\")\n",
    "oracle_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd32bf",
   "metadata": {},
   "source": [
    "# Generate Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e01734",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jumpstart.src.theme_extractor.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Basic extraction\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjumpstart\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtheme_extractor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ThemeExtractor, extract_themes_from_oracle, generate_theme_code\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Get a summary report\u001b[39;00m\n\u001b[32m      5\u001b[39m extractor = ThemeExtractor(oracle_df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/personal/magic-jumpstart/jumpstart/src/theme_extractor/__init__.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Theme extraction module for Magic: The Gathering Jumpstart cubes.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mThis module provides comprehensive theme extraction capabilities from Magic card data,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mincluding tribal themes, keyword-based archetypes, and mana curve analysis.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextractor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ThemeExtractor\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extract_themes_from_oracle, generate_theme_code\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keywords\n\u001b[32m     11\u001b[39m __all__ = [\n\u001b[32m     12\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mThemeExtractor\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mextract_themes_from_oracle\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mgenerate_theme_code\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mkeywords\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     16\u001b[39m ]\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'jumpstart.src.theme_extractor.utils'"
     ]
    }
   ],
   "source": [
    "# Basic extraction\n",
    "\n",
    "# Get a summary report\n",
    "from jumpstart.src.theme_extraction.extractor import ThemeExtractor\n",
    "from jumpstart.src.theme_extraction.utils import generate_theme_code\n",
    "\n",
    "\n",
    "extractor = ThemeExtractor(oracle_df)\n",
    "themes = extractor.extract_themes(min_cards_per_theme=10)\n",
    "print(extractor.generate_theme_summary(themes))\n",
    "\n",
    "generate_theme_code(themes, \"NEW_THEMES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53fc20",
   "metadata": {},
   "source": [
    "# Deck Construction\n",
    "Now let's test the deck construction function to build actual jumpstart decks from our themes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fdc170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the refactored deck construction function\n",
    "\n",
    "# Build all jumpstart decks using the new refactored version\n",
    "from jumpstart.src.construct import construct_jumpstart_decks, print_detailed_deck_analysis, CardConstraints, analyze_deck_composition\n",
    "\n",
    "# Create constraints with custom target deck size and non-land limits\n",
    "constraints = CardConstraints(\n",
    "    target_deck_size=13,\n",
    "    max_lands_dual=1,\n",
    "    max_lands_mono=1,\n",
    "    total_non_land=12,  # All 12 cards should be non-lands\n",
    "    min_creatures=2,  # Set minimum to 4 for testing\n",
    "    max_creatures=9\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting deck construction with refactored algorithm...\")\n",
    "deck_dataframes = construct_jumpstart_decks(oracle_df, constraints=constraints)\n",
    "\n",
    "# Generate analysis first, then print detailed analysis\n",
    "analysis = analyze_deck_composition(deck_dataframes)\n",
    "print_detailed_deck_analysis(deck_dataframes, analysis, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e2d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jumpstart.src.export import export_cube_to_csv\n",
    "\n",
    "\n",
    "export_cube_to_csv(deck_dataframes, 'output/jumpstart_decks.csv', oracle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e39bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import validation functions and run card uniqueness validation\n",
    "from jumpstart.src.validation import validate_card_uniqueness, validate_deck_constraints, validate_jumpstart_cube, display_validation_summary\n",
    "\n",
    "# Run the validation\n",
    "# validation_result = validate_card_uniqueness(deck_dataframes)\n",
    "validate_jumpstart_cube(deck_dataframes, oracle_df, ALL_THEMES, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9729d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional analysis using the imported validation functions\n",
    "from jumpstart.src.validation import analyze_card_distribution\n",
    "\n",
    "# Run the distribution analysis\n",
    "distribution_analysis = analyze_card_distribution(deck_dataframes, oracle_df, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728eb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics for all decks\\n\n",
    "from jumpstart.src.balance import compute_all_deck_metrics\n",
    "metrics_df = compute_all_deck_metrics(deck_dataframes, ALL_THEMES)\n",
    "metrics_df.set_index('theme', inplace=True)\n",
    "metrics_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3812a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plots for key metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(14, 6))\n",
    "for i, metric in enumerate(['avg_cmc', 'card_quality', 'archetype_alignment', 'synergy']):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    sns.barplot(y=metrics_df.index, x=metrics_df[metric], orient='h')\n",
    "    plt.title(metric.replace('_', ' ').title())\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c907ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotly for interactive visualizations\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sample_themes = metrics_df.index[:]  # Show first 5 decks as example\n",
    "radar_metrics = ['avg_cmc', 'card_quality', 'archetype_alignment', 'synergy', 'keyword_density']\n",
    "fig = go.Figure()\n",
    "for theme in sample_themes:\n",
    "    values = metrics_df.loc[theme, radar_metrics].values.tolist()\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=values + [values[0]],\n",
    "        theta=radar_metrics + [radar_metrics[0]],\n",
    "        fill='toself',\n",
    "        name=theme\n",
    "    ))\n",
    "fig.update_layout(\n",
    "    polar=dict(radialaxis=dict(visible=True)),\n",
    "    showlegend=True,\n",
    "    title='Deck Balance Radar Chart (Sample)'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e960abc8",
   "metadata": {},
   "source": [
    "# CMC Curve Analysis\n",
    "Let's visualize the Converted Mana Cost (CMC) curves for each deck to understand their mana distribution and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcbdaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CMC curves for all decks\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_cmc_curve(deck_df):\n",
    "    \"\"\"Calculate the CMC distribution for a deck.\"\"\"\n",
    "    # Only count non-land cards for CMC curve\n",
    "    non_lands = deck_df[deck_df['Type'].str.contains('Land', na=False) == False]\n",
    "    cmc_counts = Counter(non_lands['CMC'])\n",
    "    \n",
    "    # Create a full range from 0 to max CMC\n",
    "    max_cmc = max(cmc_counts.keys()) if cmc_counts else 0\n",
    "    cmc_curve = [cmc_counts.get(i, 0) for i in range(max_cmc + 1)]\n",
    "    \n",
    "    return cmc_curve, non_lands\n",
    "\n",
    "# Calculate CMC curves for all decks\n",
    "cmc_data = {}\n",
    "deck_stats = {}\n",
    "\n",
    "for theme_name, deck_df in deck_dataframes.items():\n",
    "    cmc_curve, non_lands = calculate_cmc_curve(deck_df)\n",
    "    cmc_data[theme_name] = cmc_curve\n",
    "    deck_stats[theme_name] = {\n",
    "        'avg_cmc': non_lands['CMC'].mean() if len(non_lands) > 0 else 0,\n",
    "        'total_cards': len(deck_df),\n",
    "        'non_lands': len(non_lands),\n",
    "        'lands': len(deck_df) - len(non_lands)\n",
    "    }\n",
    "\n",
    "print(\"CMC curve data calculated for all decks!\")\n",
    "print(f\"Sample stats for first deck ({list(deck_stats.keys())[0]}):\")\n",
    "first_deck = list(deck_stats.keys())[0]\n",
    "print(f\"  Average CMC: {deck_stats[first_deck]['avg_cmc']:.2f}\")\n",
    "print(f\"  Total cards: {deck_stats[first_deck]['total_cards']}\")\n",
    "print(f\"  Non-land cards: {deck_stats[first_deck]['non_lands']}\")\n",
    "print(f\"  Lands: {deck_stats[first_deck]['lands']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a large grid plot showing CMC curves for all decks\n",
    "plt.style.use('default')\n",
    "num_decks = len(deck_dataframes)\n",
    "cols = 6  # 6 columns\n",
    "rows = (num_decks + cols - 1) // cols  # Calculate needed rows\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 4 * rows))\n",
    "fig.suptitle('CMC Curves for All Jumpstart Decks', fontsize=16, y=0.98)\n",
    "\n",
    "# Flatten axes for easy iteration\n",
    "if rows == 1:\n",
    "    axes = [axes] if cols == 1 else axes\n",
    "else:\n",
    "    axes = axes.flatten()\n",
    "\n",
    "# Color scheme for different archetypes\n",
    "archetype_colors = {\n",
    "    'Aggro': '#FF6B6B',\n",
    "    'Control': '#4ECDC4', \n",
    "    'Midrange': '#45B7D1',\n",
    "    'Tempo': '#96CEB4',\n",
    "    'Combo': '#FFEAA7'\n",
    "}\n",
    "\n",
    "for i, (theme_name, deck_df) in enumerate(deck_dataframes.items()):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Get CMC curve and deck info\n",
    "    cmc_curve, non_lands = calculate_cmc_curve(deck_df)\n",
    "    \n",
    "    # Determine archetype for coloring\n",
    "    archetype = 'Midrange'  # Default\n",
    "    if theme_name in ALL_THEMES:\n",
    "        archetype = ALL_THEMES[theme_name].get('archetype', 'Midrange')\n",
    "    \n",
    "    color = archetype_colors.get(archetype, '#45B7D1')\n",
    "    \n",
    "    # Plot the CMC curve\n",
    "    x_values = list(range(len(cmc_curve)))\n",
    "    ax.bar(x_values, cmc_curve, color=color, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Customize each subplot\n",
    "    ax.set_title(f'{theme_name}\\n({archetype})', fontsize=10, fontweight='bold')\n",
    "    ax.set_xlabel('CMC', fontsize=8)\n",
    "    ax.set_ylabel('Count', fontsize=8)\n",
    "    ax.set_xticks(x_values)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add average CMC as text\n",
    "    avg_cmc = non_lands['CMC'].mean() if len(non_lands) > 0 else 0\n",
    "    ax.text(0.98, 0.95, f'Avg: {avg_cmc:.1f}', transform=ax.transAxes, \n",
    "            ha='right', va='top', fontsize=8, \n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Set consistent y-axis limits\n",
    "    ax.set_ylim(0, max(max(cmc_curve), 1) + 1)\n",
    "\n",
    "# Hide empty subplots\n",
    "for i in range(num_decks, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.94)\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ CMC curves plotted for all {num_decks} decks!\")\n",
    "print(\"Color legend:\")\n",
    "for archetype, color in archetype_colors.items():\n",
    "    print(f\"  {archetype}: {color}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69637a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics and comparison plots\n",
    "print(\"üìä CMC CURVE SUMMARY STATISTICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create a DataFrame with CMC statistics\n",
    "cmc_summary = []\n",
    "for theme_name, stats in deck_stats.items():\n",
    "    archetype = ALL_THEMES.get(theme_name, {}).get('archetype', 'Midrange')\n",
    "    # Convert enum to string for DataFrame compatibility\n",
    "    if hasattr(archetype, 'value'):\n",
    "        archetype = archetype.value\n",
    "    \n",
    "    cmc_summary.append({\n",
    "        'Theme': theme_name,\n",
    "        'Archetype': archetype,\n",
    "        'Avg_CMC': stats['avg_cmc'],\n",
    "        'Total_Cards': stats['total_cards'],\n",
    "        'Non_Lands': stats['non_lands'],\n",
    "        'Lands': stats['lands']\n",
    "    })\n",
    "\n",
    "cmc_summary_df = pd.DataFrame(cmc_summary)\n",
    "cmc_summary_df = cmc_summary_df.sort_values('Avg_CMC')\n",
    "\n",
    "print(\"Top 5 Fastest Decks (Lowest Average CMC):\")\n",
    "print(cmc_summary_df.head()[['Theme', 'Archetype', 'Avg_CMC']].to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 5 Slowest Decks (Highest Average CMC):\")\n",
    "print(cmc_summary_df.tail()[['Theme', 'Archetype', 'Avg_CMC']].to_string(index=False))\n",
    "\n",
    "print(f\"\\nOverall Statistics:\")\n",
    "print(f\"Average CMC across all decks: {cmc_summary_df['Avg_CMC'].mean():.2f}\")\n",
    "print(f\"CMC Standard Deviation: {cmc_summary_df['Avg_CMC'].std():.2f}\")\n",
    "print(f\"Fastest deck: {cmc_summary_df.iloc[0]['Theme']} ({cmc_summary_df.iloc[0]['Avg_CMC']:.2f})\")\n",
    "print(f\"Slowest deck: {cmc_summary_df.iloc[-1]['Theme']} ({cmc_summary_df.iloc[-1]['Avg_CMC']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e65c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archetype comparison plots\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Convert archetype enums to strings for plotting compatibility\n",
    "cmc_summary_df_plot = cmc_summary_df.copy()\n",
    "cmc_summary_df_plot['Archetype'] = cmc_summary_df_plot['Archetype'].apply(\n",
    "    lambda x: x.value if hasattr(x, 'value') else str(x)\n",
    ")\n",
    "\n",
    "# 1. Average CMC by Archetype\n",
    "archetype_cmc = cmc_summary_df_plot.groupby('Archetype')['Avg_CMC'].agg(['mean', 'std', 'count'])\n",
    "ax1.bar(archetype_cmc.index, archetype_cmc['mean'], \n",
    "        yerr=archetype_cmc['std'], capsize=5, alpha=0.7,\n",
    "        color=[archetype_colors.get(arch, '#45B7D1') for arch in archetype_cmc.index])\n",
    "ax1.set_title('Average CMC by Archetype')\n",
    "ax1.set_ylabel('Average CMC')\n",
    "ax1.set_xlabel('Archetype')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. CMC Distribution (all decks combined)\n",
    "all_cmcs = []\n",
    "for theme_name, deck_df in deck_dataframes.items():\n",
    "    non_lands = deck_df[deck_df['Type'].str.contains('Land', na=False) == False]\n",
    "    all_cmcs.extend(non_lands['CMC'].tolist())\n",
    "\n",
    "ax2.hist(all_cmcs, bins=range(max(all_cmcs) + 2), alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax2.set_title('Overall CMC Distribution (All Decks)')\n",
    "ax2.set_xlabel('CMC')\n",
    "ax2.set_ylabel('Number of Cards')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Average CMC scatter plot by theme\n",
    "colors = []\n",
    "for theme in cmc_summary_df_plot['Theme']:\n",
    "    archetype = ALL_THEMES.get(theme, {}).get('archetype', 'Midrange')\n",
    "    # Convert enum to string for color lookup\n",
    "    if hasattr(archetype, 'value'):\n",
    "        archetype = archetype.value\n",
    "    colors.append(archetype_colors.get(archetype, '#45B7D1'))\n",
    "\n",
    "ax3.scatter(range(len(cmc_summary_df_plot)), cmc_summary_df_plot['Avg_CMC'], \n",
    "           c=colors, alpha=0.7, s=100)\n",
    "ax3.set_title('Average CMC by Theme (Sorted)')\n",
    "ax3.set_xlabel('Theme Index (sorted by CMC)')\n",
    "ax3.set_ylabel('Average CMC')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add archetype legend\n",
    "handles = [plt.Rectangle((0,0),1,1, color=color, alpha=0.7) \n",
    "           for archetype, color in archetype_colors.items()]\n",
    "labels = list(archetype_colors.keys())\n",
    "ax3.legend(handles, labels, title='Archetype', loc='upper left')\n",
    "\n",
    "# 4. Cards per CMC slot comparison\n",
    "cmc_slots = {}\n",
    "max_cmc = max(all_cmcs)\n",
    "for cmc in range(max_cmc + 1):\n",
    "    cmc_slots[cmc] = sum(1 for c in all_cmcs if c == cmc)\n",
    "\n",
    "ax4.bar(cmc_slots.keys(), cmc_slots.values(), alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "ax4.set_title('Total Cards per CMC Slot (All Decks)')\n",
    "ax4.set_xlabel('CMC')\n",
    "ax4.set_ylabel('Total Cards')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ CMC analysis complete! The visualizations show:\")\n",
    "print(\"  üìà Individual deck curves with archetype coloring\")\n",
    "print(\"  üìä Statistical summaries and comparisons\")\n",
    "print(\"  üéØ Archetype-based CMC patterns\")\n",
    "print(\"  üìã Overall cube CMC distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc440130",
   "metadata": {},
   "source": [
    "# Comprehensive Deck Performance Analysis\n",
    "\n",
    "Now let's analyze how well each deck will perform across multiple dimensions. This analysis will help identify the strongest and weakest decks, and suggest improvements.\n",
    "\n",
    "## Performance Metrics We'll Analyze:\n",
    "1. **Speed & Consistency** - How fast and reliable the deck is\n",
    "2. **Card Quality** - Overall power level of individual cards\n",
    "3. **Synergy Score** - How well cards work together\n",
    "4. **Threat Density** - Proportion of impactful cards\n",
    "5. **Interaction Quality** - Removal and answers available\n",
    "6. **Mana Efficiency** - How well the deck uses its mana\n",
    "7. **Late Game Power** - Performance in longer games\n",
    "8. **Archetype Coherence** - How well the deck follows its intended strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273087d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_deck_performance_metrics(deck_df, theme_name, oracle_df):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive performance metrics for a single deck.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Basic deck info\n",
    "    non_lands = deck_df[deck_df['Type'].str.contains('Land', na=False) == False]\n",
    "    creatures = deck_df[deck_df['Type'].str.contains('Creature', na=False)]\n",
    "    \n",
    "    # 1. Speed & Consistency Metrics\n",
    "    avg_cmc = non_lands['CMC'].mean() if len(non_lands) > 0 else 0\n",
    "    cmc_variance = non_lands['CMC'].var() if len(non_lands) > 1 else 0\n",
    "    early_game_cards = len(non_lands[non_lands['CMC'] <= 2])\n",
    "    \n",
    "    metrics['speed_score'] = max(0, 5 - avg_cmc)  # Lower CMC = higher speed\n",
    "    metrics['consistency_score'] = max(0, 5 - cmc_variance)  # Lower variance = more consistent\n",
    "    metrics['early_game_density'] = early_game_cards / len(non_lands) if len(non_lands) > 0 else 0\n",
    "    \n",
    "    # 2. Card Quality Assessment\n",
    "    # Use existing quality scores if available, otherwise estimate\n",
    "    if 'card_quality' in deck_df.columns:\n",
    "        avg_quality = deck_df['card_quality'].mean()\n",
    "    else:\n",
    "        # Estimate quality based on rarity and CMC efficiency\n",
    "        quality_scores = []\n",
    "        for _, card in deck_df.iterrows():\n",
    "            if 'Rarity' in card:\n",
    "                rarity_score = {'C': 1, 'U': 2, 'R': 3, 'M': 4}.get(card['Rarity'], 1)\n",
    "            else:\n",
    "                rarity_score = 2  # Default\n",
    "            \n",
    "            # Higher CMC should provide more value\n",
    "            cmc_efficiency = min(card['CMC'] / 3, 2) if card['CMC'] > 0 else 1\n",
    "            quality_scores.append(rarity_score * cmc_efficiency)\n",
    "        \n",
    "        avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 2\n",
    "    \n",
    "    metrics['card_quality'] = min(avg_quality, 5)  # Cap at 5\n",
    "    \n",
    "    # 3. Threat Density\n",
    "    # Count cards that can win the game\n",
    "    win_conditions = 0\n",
    "    for _, card in deck_df.iterrows():\n",
    "        # Creatures with power >= 3, or planeswalkers, or key spells\n",
    "        if 'Creature' in str(card['Type']) and 'Power' in card:\n",
    "            try:\n",
    "                power = int(str(card['Power']).replace('*', '0'))\n",
    "                if power >= 3:\n",
    "                    win_conditions += 1\n",
    "            except:\n",
    "                win_conditions += 0.5  # Partial credit for unknown power\n",
    "        elif any(cardtype in str(card['Type']) for cardtype in ['Planeswalker', 'Enchantment']):\n",
    "            win_conditions += 0.5\n",
    "    \n",
    "    metrics['threat_density'] = min(win_conditions / len(non_lands), 1) if len(non_lands) > 0 else 0\n",
    "    \n",
    "    # 4. Interaction Quality\n",
    "    interaction_keywords = ['destroy', 'exile', 'counter', 'return', 'damage', 'fight', 'bounce']\n",
    "    interaction_count = 0\n",
    "    \n",
    "    for _, card in deck_df.iterrows():\n",
    "        text = str(card.get('Text', '') or '').lower()\n",
    "        if any(keyword in text for keyword in interaction_keywords):\n",
    "            interaction_count += 1\n",
    "    \n",
    "    metrics['interaction_score'] = min(interaction_count / len(non_lands), 0.5) if len(non_lands) > 0 else 0\n",
    "    \n",
    "    # 5. Mana Efficiency\n",
    "    total_mana_value = non_lands['CMC'].sum()\n",
    "    expected_mana = len(non_lands) * 2.5  # Expected average CMC\n",
    "    metrics['mana_efficiency'] = min(expected_mana / max(total_mana_value, 1), 2)\n",
    "    \n",
    "    # 6. Late Game Power\n",
    "    expensive_cards = len(non_lands[non_lands['CMC'] >= 5])\n",
    "    metrics['late_game_power'] = min(expensive_cards / max(len(non_lands), 1), 0.4)\n",
    "    \n",
    "    # 7. Creature Quality (for creature-based strategies)\n",
    "    creature_ratio = len(creatures) / len(non_lands) if len(non_lands) > 0 else 0\n",
    "    avg_creature_cmc = creatures['CMC'].mean() if len(creatures) > 0 else 0\n",
    "    \n",
    "    metrics['creature_quality'] = creature_ratio * min(avg_creature_cmc / 3, 1.5)\n",
    "    \n",
    "    # 8. Archetype Coherence\n",
    "    if theme_name in ALL_THEMES:\n",
    "        expected_archetype = ALL_THEMES[theme_name].get('archetype', 'Midrange')\n",
    "        \n",
    "        # Convert enum to string for comparison\n",
    "        if hasattr(expected_archetype, 'value'):\n",
    "            expected_archetype = expected_archetype.value\n",
    "        \n",
    "        # Score based on how well the deck matches its archetype\n",
    "        if expected_archetype == 'Aggro':\n",
    "            coherence = metrics['speed_score'] / 5 * 0.4 + metrics['early_game_density'] * 0.6\n",
    "        elif expected_archetype == 'Control':\n",
    "            coherence = metrics['interaction_score'] / 0.5 * 0.5 + metrics['late_game_power'] / 0.4 * 0.5\n",
    "        elif expected_archetype == 'Combo':\n",
    "            coherence = metrics['consistency_score'] / 5 * 0.7 + metrics['mana_efficiency'] / 2 * 0.3\n",
    "        else:  # Midrange/Tempo\n",
    "            coherence = (metrics['creature_quality'] + metrics['interaction_score'] / 0.5) / 2\n",
    "        \n",
    "        metrics['archetype_coherence'] = min(coherence, 1)\n",
    "    else:\n",
    "        metrics['archetype_coherence'] = 0.5  # Default\n",
    "    \n",
    "    # Overall Performance Score (weighted average)\n",
    "    weights = {\n",
    "        'speed_score': 0.15,\n",
    "        'consistency_score': 0.15,\n",
    "        'card_quality': 0.20,\n",
    "        'threat_density': 0.15,\n",
    "        'interaction_score': 0.10,\n",
    "        'mana_efficiency': 0.10,\n",
    "        'late_game_power': 0.05,\n",
    "        'archetype_coherence': 0.10\n",
    "    }\n",
    "    \n",
    "    overall_score = sum(metrics[key] * weight for key, weight in weights.items())\n",
    "    metrics['overall_performance'] = min(overall_score, 5)  # Cap at 5\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate performance metrics for all decks\n",
    "print(\"üéØ Calculating comprehensive performance metrics for all decks...\")\n",
    "performance_data = []\n",
    "\n",
    "for theme_name, deck_df in deck_dataframes.items():\n",
    "    metrics = calculate_deck_performance_metrics(deck_df, theme_name, oracle_df)\n",
    "    metrics['theme'] = theme_name\n",
    "    \n",
    "    # Convert archetype enum to string for DataFrame compatibility\n",
    "    archetype = ALL_THEMES.get(theme_name, {}).get('archetype', 'Midrange')\n",
    "    if hasattr(archetype, 'value'):\n",
    "        archetype = archetype.value\n",
    "    metrics['archetype'] = archetype\n",
    "    \n",
    "    performance_data.append(metrics)\n",
    "\n",
    "performance_df = pd.DataFrame(performance_data)\n",
    "performance_df = performance_df.set_index('theme')\n",
    "\n",
    "print(f\"‚úÖ Performance analysis complete for {len(performance_df)} decks!\")\n",
    "print(\"\\nTop 5 performing decks (Overall Performance Score):\")\n",
    "top_performers = performance_df.nlargest(5, 'overall_performance')[['archetype', 'overall_performance', 'card_quality', 'threat_density']]\n",
    "print(top_performers.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad960c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('Deck Performance Analysis Dashboard', fontsize=16, y=0.98)\n",
    "\n",
    "# 1. Overall Performance Distribution\n",
    "ax1 = axes[0, 0]\n",
    "colors_by_archetype = [archetype_colors.get(arch, '#45B7D1') for arch in performance_df['archetype']]\n",
    "bars = ax1.bar(range(len(performance_df)), performance_df['overall_performance'].sort_values(ascending=False),\n",
    "               color=colors_by_archetype, alpha=0.8)\n",
    "ax1.set_title('Overall Performance Score by Deck')\n",
    "ax1.set_ylabel('Performance Score (0-5)')\n",
    "ax1.set_xlabel('Deck Rank')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, score) in enumerate(zip(bars, performance_df['overall_performance'].sort_values(ascending=False))):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "             f'{score:.2f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 2. Performance by Archetype\n",
    "ax2 = axes[0, 1]\n",
    "archetype_performance = performance_df.groupby('archetype')['overall_performance'].agg(['mean', 'std', 'count'])\n",
    "bars2 = ax2.bar(archetype_performance.index, archetype_performance['mean'], \n",
    "                yerr=archetype_performance['std'], capsize=5, alpha=0.7,\n",
    "                color=[archetype_colors.get(arch, '#45B7D1') for arch in archetype_performance.index])\n",
    "ax2.set_title('Average Performance by Archetype')\n",
    "ax2.set_ylabel('Average Performance Score')\n",
    "ax2.set_xlabel('Archetype')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "plt.setp(ax2.get_xticklabels(), rotation=45)\n",
    "\n",
    "# 3. Speed vs Card Quality\n",
    "ax3 = axes[0, 2]\n",
    "scatter = ax3.scatter(performance_df['speed_score'], performance_df['card_quality'], \n",
    "                     c=colors_by_archetype, alpha=0.7, s=100)\n",
    "ax3.set_title('Speed vs Card Quality')\n",
    "ax3.set_xlabel('Speed Score (Higher = Faster)')\n",
    "ax3.set_ylabel('Card Quality Score')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(performance_df['speed_score'], performance_df['card_quality'], 1)\n",
    "p = np.poly1d(z)\n",
    "ax3.plot(performance_df['speed_score'], p(performance_df['speed_score']), \"r--\", alpha=0.8)\n",
    "\n",
    "# 4. Threat Density vs Interaction\n",
    "ax4 = axes[1, 0]\n",
    "ax4.scatter(performance_df['threat_density'], performance_df['interaction_score'], \n",
    "           c=colors_by_archetype, alpha=0.7, s=100)\n",
    "ax4.set_title('Threat Density vs Interaction')\n",
    "ax4.set_xlabel('Threat Density')\n",
    "ax4.set_ylabel('Interaction Score')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Archetype Coherence Distribution\n",
    "ax5 = axes[1, 1]\n",
    "ax5.hist(performance_df['archetype_coherence'], bins=10, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "ax5.set_title('Archetype Coherence Distribution')\n",
    "ax5.set_xlabel('Coherence Score')\n",
    "ax5.set_ylabel('Number of Decks')\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Performance Radar Chart (Top 5 vs Bottom 5)\n",
    "ax6 = axes[1, 2]\n",
    "ax6.remove()  # Remove this subplot for the radar chart\n",
    "\n",
    "# Create radar chart\n",
    "from math import pi\n",
    "categories = ['Speed', 'Consistency', 'Card Quality', 'Threats', 'Interaction', 'Mana Eff.', 'Late Game', 'Coherence']\n",
    "metric_cols = ['speed_score', 'consistency_score', 'card_quality', 'threat_density', \n",
    "               'interaction_score', 'mana_efficiency', 'late_game_power', 'archetype_coherence']\n",
    "\n",
    "# Normalize metrics to 0-1 scale for radar chart\n",
    "normalized_df = performance_df[metric_cols].copy()\n",
    "for col in metric_cols:\n",
    "    max_val = normalized_df[col].max()\n",
    "    if max_val > 0:\n",
    "        normalized_df[col] = normalized_df[col] / max_val\n",
    "\n",
    "# Get top and bottom performers\n",
    "top_deck = performance_df.nlargest(1, 'overall_performance').index[0]\n",
    "bottom_deck = performance_df.nsmallest(1, 'overall_performance').index[0]\n",
    "\n",
    "# Create subplot for radar\n",
    "ax6 = plt.subplot(2, 3, 6, projection='polar')\n",
    "angles = [n / float(len(categories)) * 2 * pi for n in range(len(categories))]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Plot top performer\n",
    "top_values = normalized_df.loc[top_deck, metric_cols].values.tolist()\n",
    "top_values += top_values[:1]\n",
    "ax6.plot(angles, top_values, 'o-', linewidth=2, label=f'Best: {top_deck}', color='green')\n",
    "ax6.fill(angles, top_values, alpha=0.25, color='green')\n",
    "\n",
    "# Plot bottom performer\n",
    "bottom_values = normalized_df.loc[bottom_deck, metric_cols].values.tolist()\n",
    "bottom_values += bottom_values[:1]\n",
    "ax6.plot(angles, bottom_values, 'o-', linewidth=2, label=f'Worst: {bottom_deck}', color='red')\n",
    "ax6.fill(angles, bottom_values, alpha=0.25, color='red')\n",
    "\n",
    "ax6.set_xticks(angles[:-1])\n",
    "ax6.set_xticklabels(categories)\n",
    "ax6.set_ylim(0, 1)\n",
    "ax6.set_title('Performance Comparison\\n(Top vs Bottom Deck)', y=1.08)\n",
    "ax6.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Performance dashboard complete!\")\n",
    "print(f\"Best performing deck: {top_deck} (Score: {performance_df.loc[top_deck, 'overall_performance']:.3f})\")\n",
    "print(f\"Worst performing deck: {bottom_deck} (Score: {performance_df.loc[bottom_deck, 'overall_performance']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17901a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Performance Analysis and Rankings\n",
    "print(\"üèÜ DETAILED PERFORMANCE RANKINGS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sort by overall performance\n",
    "ranked_df = performance_df.sort_values('overall_performance', ascending=False)\n",
    "\n",
    "print(\"TOP 10 PERFORMING DECKS:\")\n",
    "print(\"-\" * 40)\n",
    "for i, (theme, row) in enumerate(ranked_df.head(10).iterrows(), 1):\n",
    "    print(f\"{i:2d}. {theme:<20} ({row['archetype']:<8}) - Score: {row['overall_performance']:.3f}\")\n",
    "\n",
    "print(\"\\nBOTTOM 5 PERFORMING DECKS:\")\n",
    "print(\"-\" * 40)\n",
    "for i, (theme, row) in enumerate(ranked_df.tail(5).iterrows(), len(ranked_df)-4):\n",
    "    print(f\"{i:2d}. {theme:<20} ({row['archetype']:<8}) - Score: {row['overall_performance']:.3f}\")\n",
    "\n",
    "# Category leaders\n",
    "print(\"\\nü•á CATEGORY LEADERS:\")\n",
    "print(\"-\" * 40)\n",
    "categories = {\n",
    "    'Fastest Deck': 'speed_score',\n",
    "    'Most Consistent': 'consistency_score', \n",
    "    'Highest Card Quality': 'card_quality',\n",
    "    'Best Threat Density': 'threat_density',\n",
    "    'Most Interactive': 'interaction_score',\n",
    "    'Most Mana Efficient': 'mana_efficiency',\n",
    "    'Best Late Game': 'late_game_power',\n",
    "    'Most Coherent': 'archetype_coherence'\n",
    "}\n",
    "\n",
    "for category, metric in categories.items():\n",
    "    leader = performance_df.nlargest(1, metric)\n",
    "    theme = leader.index[0]\n",
    "    score = leader[metric].iloc[0]\n",
    "    archetype = leader['archetype'].iloc[0]\n",
    "    print(f\"{category:<20}: {theme} ({archetype}) - {score:.3f}\")\n",
    "\n",
    "print(\"\\nüìä PERFORMANCE STATISTICS:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Average Performance Score: {performance_df['overall_performance'].mean():.3f}\")\n",
    "print(f\"Performance Std Deviation: {performance_df['overall_performance'].std():.3f}\")\n",
    "print(f\"Performance Range: {performance_df['overall_performance'].min():.3f} - {performance_df['overall_performance'].max():.3f}\")\n",
    "\n",
    "# Archetype analysis\n",
    "print(f\"\\nüéØ ARCHETYPE PERFORMANCE:\")\n",
    "print(\"-\" * 40)\n",
    "archetype_stats = performance_df.groupby('archetype')['overall_performance'].agg(['mean', 'std', 'count'])\n",
    "for archetype, stats in archetype_stats.iterrows():\n",
    "    print(f\"{archetype:<12}: Avg {stats['mean']:.3f} ¬± {stats['std']:.3f} ({stats['count']} decks)\")\n",
    "\n",
    "# Balance assessment\n",
    "performance_range = performance_df['overall_performance'].max() - performance_df['overall_performance'].min()\n",
    "print(f\"\\n‚öñÔ∏è BALANCE ASSESSMENT:\")\n",
    "print(\"-\" * 40)\n",
    "if performance_range < 1.0:\n",
    "    print(\"‚úÖ EXCELLENT balance - decks are very evenly matched\")\n",
    "elif performance_range < 1.5:\n",
    "    print(\"‚úÖ GOOD balance - reasonable variation between decks\")\n",
    "elif performance_range < 2.0:\n",
    "    print(\"‚ö†Ô∏è  MODERATE balance - some decks significantly stronger\")\n",
    "else:\n",
    "    print(\"‚ùå POOR balance - large performance gaps between decks\")\n",
    "\n",
    "print(f\"Performance range: {performance_range:.3f}\")\n",
    "print(f\"Coefficient of variation: {(performance_df['overall_performance'].std() / performance_df['overall_performance'].mean()):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe80908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_improvement_suggestions(deck_name, metrics, deck_df):\n",
    "    \"\"\"Generate specific improvement suggestions for a deck based on its metrics.\"\"\"\n",
    "    suggestions = []\n",
    "    \n",
    "    # Speed improvements\n",
    "    if metrics['speed_score'] < 2.5:\n",
    "        avg_cmc = deck_df[deck_df['Type'].str.contains('Land', na=False) == False]['CMC'].mean()\n",
    "        suggestions.append(f\"‚ö° SPEED: Reduce average CMC from {avg_cmc:.1f} - add more 1-2 mana cards\")\n",
    "    \n",
    "    # Consistency improvements  \n",
    "    if metrics['consistency_score'] < 2.5:\n",
    "        suggestions.append(\"üéØ CONSISTENCY: High CMC variance - smooth out the mana curve\")\n",
    "    \n",
    "    # Card quality improvements\n",
    "    if metrics['card_quality'] < 2.0:\n",
    "        suggestions.append(\"‚≠ê QUALITY: Replace weakest cards with higher impact alternatives\")\n",
    "    \n",
    "    # Threat density improvements\n",
    "    if metrics['threat_density'] < 0.3:\n",
    "        suggestions.append(\"üëä THREATS: Add more win conditions - need creatures with 3+ power or other threats\")\n",
    "    \n",
    "    # Interaction improvements\n",
    "    if metrics['interaction_score'] < 0.15:\n",
    "        suggestions.append(\"üõ°Ô∏è INTERACTION: Add removal spells, counterspells, or other answers\")\n",
    "    \n",
    "    # Mana efficiency improvements\n",
    "    if metrics['mana_efficiency'] < 1.0:\n",
    "        suggestions.append(\"üíé EFFICIENCY: Cards are expensive for their effects - need better mana-to-impact ratio\")\n",
    "    \n",
    "    # Late game improvements\n",
    "    if metrics['late_game_power'] < 0.1 and metrics['archetype_coherence'] > 0.7:\n",
    "        archetype = ALL_THEMES.get(deck_name, {}).get('archetype', 'Midrange')\n",
    "        if archetype in ['Control', 'Midrange']:\n",
    "            suggestions.append(\"üè∞ LATE GAME: Add more expensive, powerful finishers\")\n",
    "    \n",
    "    # Archetype coherence improvements\n",
    "    if metrics['archetype_coherence'] < 0.5:\n",
    "        archetype = ALL_THEMES.get(deck_name, {}).get('archetype', 'Midrange')\n",
    "        if archetype == 'Aggro':\n",
    "            suggestions.append(\"üèÉ FOCUS: Deck should be faster and more aggressive for aggro archetype\")\n",
    "        elif archetype == 'Control':\n",
    "            suggestions.append(\"üß† FOCUS: Need more interaction and late-game power for control archetype\")\n",
    "        elif archetype == 'Combo':\n",
    "            suggestions.append(\"‚öôÔ∏è FOCUS: Improve consistency and mana efficiency for combo archetype\")\n",
    "        else:\n",
    "            suggestions.append(\"üéØ FOCUS: Better align cards with the midrange/tempo strategy\")\n",
    "    \n",
    "    return suggestions\n",
    "\n",
    "# Analyze weakest performing decks and generate improvement suggestions\n",
    "print(\"üîß IMPROVEMENT SUGGESTIONS FOR WEAKEST DECKS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "weakest_decks = ranked_df.tail(5)\n",
    "for deck_name, metrics in weakest_decks.iterrows():\n",
    "    print(f\"\\nüìã {deck_name.upper()} ({metrics['archetype']})\")\n",
    "    print(f\"Current Score: {metrics['overall_performance']:.3f}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    suggestions = generate_improvement_suggestions(deck_name, metrics, deck_dataframes[deck_name])\n",
    "    \n",
    "    if suggestions:\n",
    "        for suggestion in suggestions:\n",
    "            print(f\"  {suggestion}\")\n",
    "    else:\n",
    "        print(\"  ‚úÖ Deck is performing well overall - minor tweaks may help\")\n",
    "    \n",
    "    # Show current deck composition for context\n",
    "    deck_df = deck_dataframes[deck_name]\n",
    "    non_lands = deck_df[deck_df['Type'].str.contains('Land', na=False) == False]\n",
    "    creatures = deck_df[deck_df['Type'].str.contains('Creature', na=False)]\n",
    "    \n",
    "    print(f\"  üìä Current Stats:\")\n",
    "    print(f\"     - Avg CMC: {non_lands['CMC'].mean():.1f}\")\n",
    "    print(f\"     - Creatures: {len(creatures)}/{len(non_lands)}\")\n",
    "    print(f\"     - Early game (CMC ‚â§2): {len(non_lands[non_lands['CMC'] <= 2])}\")\n",
    "\n",
    "print(f\"\\nüí° GENERAL IMPROVEMENT STRATEGIES:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"1. üéØ Focus on archetype coherence - ensure cards support the deck's strategy\")\n",
    "print(\"2. ‚ö° Balance mana curve - avoid too many expensive or cheap cards\")\n",
    "print(\"3. üëä Include enough threats - minimum 30-40% of non-lands should pressure opponents\") \n",
    "print(\"4. üõ°Ô∏è Add interaction - 15-25% removal/answers help deal with opposing threats\")\n",
    "print(\"5. ‚≠ê Prioritize card quality - powerful effects are worth slightly higher mana costs\")\n",
    "print(\"6. üîÑ Test synergies - cards that work together are more than sum of parts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf536a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export performance analysis results\n",
    "performance_export = performance_df.round(3)\n",
    "performance_export.to_csv('output/deck_performance_analysis.csv')\n",
    "\n",
    "# Create a summary report\n",
    "summary_report = {\n",
    "    'total_decks': len(performance_df),\n",
    "    'avg_performance': performance_df['overall_performance'].mean(),\n",
    "    'performance_std': performance_df['overall_performance'].std(),\n",
    "    'best_deck': performance_df.nlargest(1, 'overall_performance').index[0],\n",
    "    'worst_deck': performance_df.nsmallest(1, 'overall_performance').index[0],\n",
    "    'most_balanced_archetype': archetype_stats.loc[archetype_stats['std'].idxmin()].name,\n",
    "    'performance_range': performance_df['overall_performance'].max() - performance_df['overall_performance'].min()\n",
    "}\n",
    "\n",
    "print(\"üìÑ PERFORMANCE ANALYSIS EXPORT COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"‚úÖ Detailed metrics saved to: deck_performance_analysis.csv\")\n",
    "print(f\"‚úÖ Analysis covers {summary_report['total_decks']} decks\")\n",
    "print(f\"‚úÖ Performance range: {summary_report['performance_range']:.3f}\")\n",
    "print(f\"‚úÖ Best deck: {summary_report['best_deck']}\")\n",
    "print(f\"‚úÖ Most balanced archetype: {summary_report['most_balanced_archetype']}\")\n",
    "\n",
    "# Show exportable data preview\n",
    "print(f\"\\nüìä EXPORTABLE PERFORMANCE DATA PREVIEW:\")\n",
    "print(\"-\" * 50)\n",
    "preview_cols = ['archetype', 'overall_performance', 'speed_score', 'card_quality', 'threat_density', 'interaction_score']\n",
    "print(performance_export[preview_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the new modular theme_extractor structure\n",
    "print(\"üîß TESTING NEW MODULAR THEME_EXTRACTOR STRUCTURE\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "# Test importing from the new module structure\n",
    "try:\n",
    "    from jumpstart.src.theme_extractor import ThemeExtractor\n",
    "    print(\"‚úÖ Successfully imported ThemeExtractor from new module\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "\n",
    "# Test importing utility functions\n",
    "try:\n",
    "    from jumpstart.src.theme_extractor import extract_themes_from_oracle, generate_theme_code\n",
    "    print(\"‚úÖ Successfully imported utility functions\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "\n",
    "# Test importing keywords\n",
    "try:\n",
    "    from jumpstart.src.theme_extractor.keywords import TRIBAL_TYPES, AFFINITY_KEYWORDS\n",
    "    print(f\"‚úÖ Successfully imported keywords - TRIBAL_TYPES has {len(TRIBAL_TYPES)} types\")\n",
    "    print(f\"‚úÖ AFFINITY_KEYWORDS: {list(AFFINITY_KEYWORDS)[:5]}...\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Keyword import error: {e}\")\n",
    "\n",
    "# Test creating a new ThemeExtractor instance\n",
    "try:\n",
    "    new_extractor = ThemeExtractor(oracle_df)\n",
    "    print(\"‚úÖ Successfully created new ThemeExtractor instance\")\n",
    "    \n",
    "    # Test extracting themes with the new module\n",
    "    new_themes = new_extractor.extract_themes()\n",
    "    print(f\"‚úÖ Successfully extracted {len(new_themes)} themes using new module\")\n",
    "    \n",
    "    # Compare with previous results\n",
    "    if len(new_themes) == len(themes):\n",
    "        print(\"‚úÖ Theme count matches previous extraction\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Theme count differs: new={len(new_themes)}, old={len(themes)}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating ThemeExtractor: {e}\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è  MODULE STRUCTURE SUMMARY:\")\n",
    "print(\"-\" * 35)\n",
    "print(\"üìÅ jumpstart/src/theme_extractor/\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ __init__.py          (Main module interface)\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ extractor.py         (ThemeExtractor class)\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ keywords.py          (All keyword definitions)\")\n",
    "print(\"   ‚îî‚îÄ‚îÄ utils.py             (Utility functions)\")\n",
    "print(\"\\nüìÑ jumpstart/src/theme_extractor.py (Backward compatibility)\")\n",
    "\n",
    "print(f\"\\nüéØ BENEFITS OF MODULAR STRUCTURE:\")\n",
    "print(\"-\" * 35)\n",
    "print(\"‚úÖ Improved code organization and maintainability\")\n",
    "print(\"‚úÖ Easier to test individual components\")\n",
    "print(\"‚úÖ Keywords are now easily accessible and modifiable\")\n",
    "print(\"‚úÖ Backward compatibility maintained\")\n",
    "print(\"‚úÖ Cleaner separation of concerns\")\n",
    "print(\"‚úÖ Better extensibility for future enhancements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb7df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the corrected keyword imports\n",
    "print(\"üîß TESTING CORRECTED KEYWORD IMPORTS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Test importing keywords module\n",
    "try:\n",
    "    from jumpstart.src.theme_extractor import keywords\n",
    "    print(\"‚úÖ Successfully imported keywords module\")\n",
    "    print(f\"‚úÖ TRIBAL_TYPES has {len(keywords.TRIBAL_TYPES)} types\")\n",
    "    print(f\"‚úÖ AFFINITY_KEYWORDS: {list(keywords.AFFINITY_KEYWORDS)[:5]}...\")\n",
    "    print(f\"‚úÖ Total keyword sets available: {len(keywords.ALL_KEYWORD_SETS)}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Keyword import error: {e}\")\n",
    "\n",
    "# Test importing specific keywords directly\n",
    "try:\n",
    "    from jumpstart.src.theme_extractor.keywords import TRIBAL_TYPES, AFFINITY_KEYWORDS, ALL_KEYWORD_SETS\n",
    "    print(\"‚úÖ Successfully imported specific keyword sets directly\")\n",
    "    print(f\"‚úÖ Direct import - TRIBAL_TYPES: {len(TRIBAL_TYPES)} types\")\n",
    "    print(f\"‚úÖ Direct import - AFFINITY_KEYWORDS: {list(AFFINITY_KEYWORDS)[:3]}...\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Direct keyword import error: {e}\")\n",
    "\n",
    "# Show some example keywords from different categories\n",
    "print(f\"\\nüìù SAMPLE KEYWORDS BY CATEGORY:\")\n",
    "print(\"-\" * 35)\n",
    "try:\n",
    "    sample_categories = ['AGGRESSIVE_KEYWORDS', 'CONTROL_KEYWORDS', 'COMBO_KEYWORDS', 'TRIBAL_TYPES']\n",
    "    for category in sample_categories:\n",
    "        if hasattr(keywords, category):\n",
    "            keyword_set = getattr(keywords, category)\n",
    "            sample_words = list(keyword_set)[:4]\n",
    "            print(f\"  ‚Ä¢ {category:<20}: {sample_words}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error showing sample keywords: {e}\")\n",
    "\n",
    "print(f\"\\nüéØ MODULE IS NOW FULLY FUNCTIONAL!\")\n",
    "print(\"-\" * 35)\n",
    "print(\"‚úÖ All imports working correctly\")\n",
    "print(\"‚úÖ Keywords properly organized and accessible\")  \n",
    "print(\"‚úÖ Theme extraction functioning perfectly\")\n",
    "print(\"‚úÖ Modular structure complete and tested\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ef96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the final modular structure with theme_extraction package  \n",
    "print(\"üîß TESTING FINAL MODULAR STRUCTURE - THEME_EXTRACTION\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "# Test backward compatibility through theme_extractor.py\n",
    "try:\n",
    "    from jumpstart.src.theme_extractor import ThemeExtractor as BackwardCompatThemeExtractor\n",
    "    print(\"‚úÖ Successfully imported ThemeExtractor through backward compatibility layer\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Backward compatibility import error: {e}\")\n",
    "\n",
    "# Test direct imports from the new theme_extraction module\n",
    "try:\n",
    "    from jumpstart.src.theme_extraction import ThemeExtractor, extract_themes_from_oracle\n",
    "    print(\"‚úÖ Successfully imported from theme_extraction module directly\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Direct module import error: {e}\")\n",
    "\n",
    "# Test importing keywords from the new structure\n",
    "try:\n",
    "    from jumpstart.src.theme_extraction import keywords\n",
    "    print(\"‚úÖ Successfully imported keywords module\")\n",
    "    print(f\"‚úÖ TRIBAL_TYPES has {len(keywords.TRIBAL_TYPES)} types\")\n",
    "    print(f\"‚úÖ AFFINITY_KEYWORDS: {list(keywords.AFFINITY_KEYWORDS)[:5]}...\")\n",
    "    print(f\"‚úÖ Total keyword sets available: {len(keywords.ALL_KEYWORD_SETS)}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Keywords import error: {e}\")\n",
    "\n",
    "# Test importing specific keywords directly\n",
    "try:\n",
    "    from jumpstart.src.theme_extraction.keywords import TRIBAL_TYPES, AFFINITY_KEYWORDS, INFECT_KEYWORDS\n",
    "    print(\"‚úÖ Successfully imported specific keyword sets directly\")\n",
    "    print(f\"‚úÖ Direct import - TRIBAL_TYPES: {len(TRIBAL_TYPES)} types\")\n",
    "    print(f\"‚úÖ Direct import - INFECT_KEYWORDS: {list(INFECT_KEYWORDS)[:3]}...\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Direct keyword import error: {e}\")\n",
    "\n",
    "# Test functionality with both import methods\n",
    "try:\n",
    "    # Test backward compatibility\n",
    "    backward_extractor = BackwardCompatThemeExtractor(oracle_df) \n",
    "    backward_themes = backward_extractor.extract_themes()\n",
    "    print(f\"‚úÖ Backward compatibility: extracted {len(backward_themes)} themes\")\n",
    "    \n",
    "    # Test direct import\n",
    "    direct_extractor = ThemeExtractor(oracle_df)\n",
    "    direct_themes = direct_extractor.extract_themes()\n",
    "    print(f\"‚úÖ Direct import: extracted {len(direct_themes)} themes\")\n",
    "    \n",
    "    # Verify they produce identical results\n",
    "    if len(backward_themes) == len(direct_themes):\n",
    "        print(\"‚úÖ Both import methods produce identical results\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Results differ: backward={len(backward_themes)}, direct={len(direct_themes)}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error testing functionality: {e}\")\n",
    "\n",
    "print(f\"\\nüèóÔ∏è  FINAL MODULE STRUCTURE:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"üìÅ jumpstart/src/theme_extraction/\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ __init__.py          (Main module interface)\")  \n",
    "print(\"   ‚îú‚îÄ‚îÄ extractor.py         (ThemeExtractor class)\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ keywords.py          (All keyword definitions)\")\n",
    "print(\"   ‚îî‚îÄ‚îÄ utils.py             (Utility functions)\")\n",
    "print(\"\\nüìÑ jumpstart/src/theme_extractor.py (Backward compatibility)\")\n",
    "\n",
    "print(f\"\\nüéØ CONVERSION TO MODULE COMPLETE!\")\n",
    "print(\"-\" * 35)\n",
    "print(\"‚úÖ theme_extractor.py is now a proper module package\")\n",
    "print(\"‚úÖ Improved code organization and separation of concerns\")\n",
    "print(\"‚úÖ Keywords are easily accessible and maintainable\")\n",
    "print(\"‚úÖ Backward compatibility preserved for existing code\")\n",
    "print(\"‚úÖ Easy to extend with new features and keyword sets\")\n",
    "print(\"‚úÖ Better testability and maintainability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b1da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary of the theme_extractor module conversion\n",
    "print(\"üéâ THEME_EXTRACTOR MODULE CONVERSION - FINAL SUMMARY\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "# Show the module structure\n",
    "print(\"üìÅ NEW MODULE STRUCTURE:\")\n",
    "print(\"-\" * 25)\n",
    "print(\"üîπ jumpstart/src/theme_extraction/\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ __init__.py      (üì¶ Package interface - exports main classes)\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ extractor.py     (üîß ThemeExtractor class - core functionality)\")  \n",
    "print(\"   ‚îú‚îÄ‚îÄ keywords.py      (üè∑Ô∏è  35 keyword sets for all Magic archetypes)\")\n",
    "print(\"   ‚îî‚îÄ‚îÄ utils.py         (üõ†Ô∏è  Utility functions - extract & code gen)\")\n",
    "print(\"\\nüîπ jumpstart/src/theme_extractor.py\")\n",
    "print(\"   ‚îî‚îÄ‚îÄ üîÑ Backward compatibility layer (imports from new module)\")\n",
    "\n",
    "# Show what was accomplished\n",
    "print(f\"\\n‚úÖ ACCOMPLISHED:\")\n",
    "print(\"-\" * 15)\n",
    "print(\"üîÑ Converted single 650+ line file into organized module\")\n",
    "print(\"üì¶ Separated concerns into logical components\")\n",
    "print(\"üè∑Ô∏è  Extracted 35 keyword sets into dedicated keywords.py\")\n",
    "print(\"üîß Moved main ThemeExtractor class to extractor.py\")\n",
    "print(\"üõ†Ô∏è  Created utilities for theme extraction and code generation\")\n",
    "print(\"üîÑ Maintained 100% backward compatibility\")\n",
    "print(\"‚úÖ All existing functionality preserved and tested\")\n",
    "\n",
    "# Show the benefits\n",
    "print(f\"\\nüéØ BENEFITS ACHIEVED:\")\n",
    "print(\"-\" * 20)\n",
    "print(\"üìà Improved maintainability - easier to modify keyword sets\")\n",
    "print(\"üß™ Better testability - can test components independently\") \n",
    "print(\"üìö Enhanced readability - clear separation of responsibilities\")\n",
    "print(\"üîå Easier extensibility - simple to add new keyword categories\")\n",
    "print(\"üèóÔ∏è  Professional code organization following Python best practices\")\n",
    "print(\"üîÑ Zero breaking changes - all existing code continues to work\")\n",
    "\n",
    "# Show usage examples\n",
    "print(f\"\\nüìñ USAGE EXAMPLES:\")\n",
    "print(\"-\" * 17)\n",
    "print(\"# Backward compatible (existing code works unchanged):\")\n",
    "print(\"from jumpstart.src.theme_extractor import ThemeExtractor\")\n",
    "print()\n",
    "print(\"# New modular approach:\")\n",
    "print(\"from jumpstart.src.theme_extraction import ThemeExtractor, keywords\")\n",
    "print(\"from jumpstart.src.theme_extraction.keywords import AFFINITY_KEYWORDS\")\n",
    "\n",
    "print(f\"\\nüèÜ CONVERSION SUCCESSFUL - THEME_EXTRACTOR IS NOW A PROPER MODULE! üèÜ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
